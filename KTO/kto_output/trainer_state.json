{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.997979797979798,
  "eval_steps": 100,
  "global_step": 247,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020202020202020204,
      "grad_norm": 9.02208137512207,
      "kl": 4.685591697692871,
      "learning_rate": 4.996765239312761e-07,
      "logits/chosen": 12775916.873563219,
      "logits/rejected": 9450788.821917808,
      "logps/chosen": -67.64139390265805,
      "logps/rejected": -87.95364003638699,
      "loss": 0.5038,
      "num_input_tokens_seen": 128704,
      "rewards/chosen": -0.016668319702148438,
      "rewards/margins": -0.0434795275126418,
      "rewards/rejected": 0.026811207810493363,
      "step": 5
    },
    {
      "epoch": 0.04040404040404041,
      "grad_norm": 8.839459419250488,
      "kl": 6.954946517944336,
      "learning_rate": 4.983638369387449e-07,
      "logits/chosen": 13842016.780487806,
      "logits/rejected": 25975213.948717948,
      "logps/chosen": -67.77616472942073,
      "logps/rejected": -85.57530799278847,
      "loss": 0.4974,
      "num_input_tokens_seen": 256128,
      "rewards/chosen": 0.09204157387338034,
      "rewards/margins": 0.039114189863652275,
      "rewards/rejected": 0.052927384009728067,
      "step": 10
    },
    {
      "epoch": 0.06060606060606061,
      "grad_norm": 11.11247730255127,
      "kl": 6.872073173522949,
      "learning_rate": 4.960470248207076e-07,
      "logits/chosen": 10835954.120481927,
      "logits/rejected": 21112813.714285713,
      "logps/chosen": -70.93362904743977,
      "logps/rejected": -87.06780768060065,
      "loss": 0.4984,
      "num_input_tokens_seen": 384736,
      "rewards/chosen": 0.028564016503023815,
      "rewards/margins": 0.02671909018910336,
      "rewards/rejected": 0.0018449263139204545,
      "step": 15
    },
    {
      "epoch": 0.08080808080808081,
      "grad_norm": 11.494790077209473,
      "kl": 5.634124755859375,
      "learning_rate": 4.92735454356513e-07,
      "logits/chosen": 6932386.909090909,
      "logits/rejected": -838269.4444444445,
      "logps/chosen": -67.68727805397727,
      "logps/rejected": -87.78535970052083,
      "loss": 0.4949,
      "num_input_tokens_seen": 516352,
      "rewards/chosen": 0.05141327597878196,
      "rewards/margins": 0.04967769468673552,
      "rewards/rejected": 0.001735581292046441,
      "step": 20
    },
    {
      "epoch": 0.10101010101010101,
      "grad_norm": 11.331802368164062,
      "kl": 6.683119773864746,
      "learning_rate": 4.884425140939826e-07,
      "logits/chosen": 10216471.272727273,
      "logits/rejected": 1998899.6626506024,
      "logps/chosen": -68.3638773336039,
      "logps/rejected": -86.0310735128012,
      "loss": 0.5005,
      "num_input_tokens_seen": 646240,
      "rewards/chosen": 0.058912500158532874,
      "rewards/margins": -0.01041222305071035,
      "rewards/rejected": 0.06932472320924322,
      "step": 25
    },
    {
      "epoch": 0.12121212121212122,
      "grad_norm": 59.317935943603516,
      "kl": 6.743112564086914,
      "learning_rate": 4.831855602200435e-07,
      "logits/chosen": -3741233.951219512,
      "logits/rejected": 23378875.076923076,
      "logps/chosen": -64.6145614996189,
      "logps/rejected": -84.40608723958333,
      "loss": 0.4993,
      "num_input_tokens_seen": 777088,
      "rewards/chosen": 0.026614863698075458,
      "rewards/margins": 0.01713199090629611,
      "rewards/rejected": 0.009482872791779347,
      "step": 30
    },
    {
      "epoch": 0.1414141414141414,
      "grad_norm": 9.4202299118042,
      "kl": 5.051074028015137,
      "learning_rate": 4.76985846390355e-07,
      "logits/chosen": 16048749.037037037,
      "logits/rejected": 743086.7848101265,
      "logps/chosen": -67.28328751929013,
      "logps/rejected": -85.59365110759494,
      "loss": 0.4785,
      "num_input_tokens_seen": 907680,
      "rewards/chosen": 0.14103131235381702,
      "rewards/margins": 0.18069581021217837,
      "rewards/rejected": -0.039664497858361354,
      "step": 35
    },
    {
      "epoch": 0.16161616161616163,
      "grad_norm": 12.512834548950195,
      "kl": 5.852945327758789,
      "learning_rate": 4.698684378016222e-07,
      "logits/chosen": 8003638.613333333,
      "logits/rejected": 25611113.411764707,
      "logps/chosen": -67.376328125,
      "logps/rejected": -86.24458869485294,
      "loss": 0.4802,
      "num_input_tokens_seen": 1034912,
      "rewards/chosen": 0.19918927510579426,
      "rewards/margins": 0.1670217955346201,
      "rewards/rejected": 0.032167479571174176,
      "step": 40
    },
    {
      "epoch": 0.18181818181818182,
      "grad_norm": 8.282970428466797,
      "kl": 8.34848403930664,
      "learning_rate": 4.618621098540022e-07,
      "logits/chosen": 1780053.0731707318,
      "logits/rejected": 6799042.871794872,
      "logps/chosen": -67.0495665015244,
      "logps/rejected": -85.2576434795673,
      "loss": 0.4924,
      "num_input_tokens_seen": 1166656,
      "rewards/chosen": 0.1346955880886171,
      "rewards/margins": 0.08782369364344231,
      "rewards/rejected": 0.046871894445174776,
      "step": 45
    },
    {
      "epoch": 0.20202020202020202,
      "grad_norm": 10.931364059448242,
      "kl": 6.985674858093262,
      "learning_rate": 4.5299923181330405e-07,
      "logits/chosen": -356754.3157894737,
      "logits/rejected": 16986991.23809524,
      "logps/chosen": -68.49586245888158,
      "logps/rejected": -86.29795619419643,
      "loss": 0.4949,
      "num_input_tokens_seen": 1296032,
      "rewards/chosen": 0.10506574731124074,
      "rewards/margins": 0.04089802070369099,
      "rewards/rejected": 0.06416772660754975,
      "step": 50
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 10.009795188903809,
      "kl": 7.255476951599121,
      "learning_rate": 4.4331563594333336e-07,
      "logits/chosen": 22690415.376623377,
      "logits/rejected": 18649905.34939759,
      "logps/chosen": -68.69431057224025,
      "logps/rejected": -85.99029320406626,
      "loss": 0.4979,
      "num_input_tokens_seen": 1423616,
      "rewards/chosen": 0.10638152778922737,
      "rewards/margins": 0.03143950199562326,
      "rewards/rejected": 0.07494202579360411,
      "step": 55
    },
    {
      "epoch": 0.24242424242424243,
      "grad_norm": 15.064253807067871,
      "kl": 7.233914375305176,
      "learning_rate": 4.3285047263747327e-07,
      "logits/chosen": 12239798.857142856,
      "logits/rejected": 6511962.987951808,
      "logps/chosen": -67.5702237215909,
      "logps/rejected": -85.78081466490964,
      "loss": 0.4911,
      "num_input_tokens_seen": 1552160,
      "rewards/chosen": 0.11201600904588575,
      "rewards/margins": 0.07311942539683644,
      "rewards/rejected": 0.03889658364904932,
      "step": 60
    },
    {
      "epoch": 0.26262626262626265,
      "grad_norm": 8.577860832214355,
      "kl": 9.179040908813477,
      "learning_rate": 4.216460521351992e-07,
      "logits/chosen": 1061397.3333333333,
      "logits/rejected": 11674843.178082192,
      "logps/chosen": -67.96321614583333,
      "logps/rejected": -83.98775283604452,
      "loss": 0.4867,
      "num_input_tokens_seen": 1681088,
      "rewards/chosen": 0.18565888240419584,
      "rewards/margins": 0.10569765436013014,
      "rewards/rejected": 0.0799612280440657,
      "step": 65
    },
    {
      "epoch": 0.2828282828282828,
      "grad_norm": 10.123412132263184,
      "kl": 9.062660217285156,
      "learning_rate": 4.0974767346346197e-07,
      "logits/chosen": 11675564.307692308,
      "logits/rejected": 24220309.85365854,
      "logps/chosen": -64.12557592147436,
      "logps/rejected": -84.3795731707317,
      "loss": 0.4816,
      "num_input_tokens_seen": 1809728,
      "rewards/chosen": 0.18903096516927084,
      "rewards/margins": 0.1343258338245919,
      "rewards/rejected": 0.05470513134467893,
      "step": 70
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 11.442017555236816,
      "kl": 8.304204940795898,
      "learning_rate": 3.972034412945211e-07,
      "logits/chosen": 24608818.285714287,
      "logits/rejected": -12203855.157894736,
      "logps/chosen": -67.40008254278274,
      "logps/rejected": -84.41316303453948,
      "loss": 0.4939,
      "num_input_tokens_seen": 1939008,
      "rewards/chosen": 0.1340703737168085,
      "rewards/margins": 0.03582517963304256,
      "rewards/rejected": 0.09824519408376593,
      "step": 75
    },
    {
      "epoch": 0.32323232323232326,
      "grad_norm": 9.215941429138184,
      "kl": 8.900805473327637,
      "learning_rate": 3.8406407146066634e-07,
      "logits/chosen": 15608032.438356165,
      "logits/rejected": 15966693.51724138,
      "logps/chosen": -67.79269450984589,
      "logps/rejected": -85.56401535560344,
      "loss": 0.4804,
      "num_input_tokens_seen": 2068704,
      "rewards/chosen": 0.17917029498374626,
      "rewards/margins": 0.14310739667673522,
      "rewards/rejected": 0.036062898307011045,
      "step": 80
    },
    {
      "epoch": 0.3434343434343434,
      "grad_norm": 9.711365699768066,
      "kl": 11.532959938049316,
      "learning_rate": 3.703826859121224e-07,
      "logits/chosen": 5417317.333333333,
      "logits/rejected": 17555198.43902439,
      "logps/chosen": -67.87724108573718,
      "logps/rejected": -85.2779570788872,
      "loss": 0.4818,
      "num_input_tokens_seen": 2196800,
      "rewards/chosen": 0.2791539705716647,
      "rewards/margins": 0.1514563748357891,
      "rewards/rejected": 0.12769759573587558,
      "step": 85
    },
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 15.74500560760498,
      "kl": 8.036569595336914,
      "learning_rate": 3.5621459794711485e-07,
      "logits/chosen": 10064271.157894736,
      "logits/rejected": 15945633.523809524,
      "logps/chosen": -67.95362613075658,
      "logps/rejected": -85.230712890625,
      "loss": 0.4875,
      "num_input_tokens_seen": 2326080,
      "rewards/chosen": 0.19558708291304738,
      "rewards/margins": 0.11116061174779905,
      "rewards/rejected": 0.08442647116524833,
      "step": 90
    },
    {
      "epoch": 0.3838383838383838,
      "grad_norm": 12.08868408203125,
      "kl": 8.206352233886719,
      "learning_rate": 3.416170885824028e-07,
      "logits/chosen": -914978.88,
      "logits/rejected": 13581721.6,
      "logps/chosen": -65.06444010416666,
      "logps/rejected": -84.93735064338236,
      "loss": 0.4857,
      "num_input_tokens_seen": 2455424,
      "rewards/chosen": 0.2527138010660807,
      "rewards/margins": 0.14784191655177695,
      "rewards/rejected": 0.10487188451430376,
      "step": 95
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 11.047459602355957,
      "kl": 7.4855241775512695,
      "learning_rate": 3.266491749684038e-07,
      "logits/chosen": 30919141.743589744,
      "logits/rejected": 14218227.512195121,
      "logps/chosen": -67.90513571714743,
      "logps/rejected": -84.8016387195122,
      "loss": 0.4848,
      "num_input_tokens_seen": 2584128,
      "rewards/chosen": 0.1538687363649026,
      "rewards/margins": 0.12249734060252881,
      "rewards/rejected": 0.031371395762373765,
      "step": 100
    },
    {
      "epoch": 0.40404040404040403,
      "eval_logits/chosen": 21281509.463414636,
      "eval_logits/rejected": 9404417.641025642,
      "eval_logps/chosen": -66.90168278391768,
      "eval_logps/rejected": -83.4656262520032,
      "eval_loss": 0.4704577326774597,
      "eval_rewards/chosen": 0.3227360423018293,
      "eval_rewards/margins": 0.24225077172828663,
      "eval_rewards/rejected": 0.08048527057354267,
      "eval_runtime": 23.7962,
      "eval_samples_per_second": 3.362,
      "eval_steps_per_second": 0.84,
      "kl": 5.372583389282227,
      "num_input_tokens_seen": 2584128,
      "step": 100
    },
    {
      "epoch": 0.42424242424242425,
      "grad_norm": 11.424247741699219,
      "kl": 9.838242530822754,
      "learning_rate": 3.1137137178519977e-07,
      "logits/chosen": 18032721.012658227,
      "logits/rejected": 4863917.037037037,
      "logps/chosen": -68.58298927017405,
      "logps/rejected": -86.36616271219135,
      "loss": 0.4752,
      "num_input_tokens_seen": 2714464,
      "rewards/chosen": 0.2796238042131255,
      "rewards/margins": 0.18858094415845006,
      "rewards/rejected": 0.09104286005467545,
      "step": 105
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 12.221531867980957,
      "kl": 9.933326721191406,
      "learning_rate": 2.9584544658408903e-07,
      "logits/chosen": 17310461.09090909,
      "logits/rejected": 3231754.0,
      "logps/chosen": -67.64298872514205,
      "logps/rejected": -85.47808837890625,
      "loss": 0.4771,
      "num_input_tokens_seen": 2844320,
      "rewards/chosen": 0.22785388339649548,
      "rewards/margins": 0.17921832113554984,
      "rewards/rejected": 0.04863556226094564,
      "step": 110
    },
    {
      "epoch": 0.46464646464646464,
      "grad_norm": 8.558917999267578,
      "kl": 9.016329765319824,
      "learning_rate": 2.801341700638307e-07,
      "logits/chosen": 14424836.383561645,
      "logits/rejected": 20943208.459770113,
      "logps/chosen": -65.52438730736301,
      "logps/rejected": -83.4643835308908,
      "loss": 0.4722,
      "num_input_tokens_seen": 2971840,
      "rewards/chosen": 0.28773007327563144,
      "rewards/margins": 0.21189902174512226,
      "rewards/rejected": 0.07583105153050916,
      "step": 115
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 14.11108112335205,
      "kl": 9.044853210449219,
      "learning_rate": 2.6430106229120367e-07,
      "logits/chosen": 92590.02247191011,
      "logits/rejected": 8219881.464788732,
      "logps/chosen": -64.53295075491573,
      "logps/rejected": -87.41648327464789,
      "loss": 0.4806,
      "num_input_tokens_seen": 3100288,
      "rewards/chosen": 0.21479895945345417,
      "rewards/margins": 0.13878953145602624,
      "rewards/rejected": 0.07600942799742792,
      "step": 120
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 11.404845237731934,
      "kl": 8.548327445983887,
      "learning_rate": 2.4841013589189975e-07,
      "logits/chosen": 18599358.43902439,
      "logits/rejected": 20901663.17948718,
      "logps/chosen": -69.18441549161585,
      "logps/rejected": -82.62439903846153,
      "loss": 0.4739,
      "num_input_tokens_seen": 3229792,
      "rewards/chosen": 0.2885823831325624,
      "rewards/margins": 0.22512988256916094,
      "rewards/rejected": 0.06345250056340145,
      "step": 125
    },
    {
      "epoch": 0.5252525252525253,
      "grad_norm": 10.544927597045898,
      "kl": 12.140678405761719,
      "learning_rate": 2.3252563725002103e-07,
      "logits/chosen": 719537.095890411,
      "logits/rejected": 23090406.988505747,
      "logps/chosen": -67.44454997859589,
      "logps/rejected": -85.13806012033046,
      "loss": 0.4695,
      "num_input_tokens_seen": 3358752,
      "rewards/chosen": 0.37526509533189745,
      "rewards/margins": 0.2384781850227088,
      "rewards/rejected": 0.13678691030918866,
      "step": 130
    },
    {
      "epoch": 0.5454545454545454,
      "grad_norm": 13.539046287536621,
      "kl": 7.2924346923828125,
      "learning_rate": 2.1671178676250235e-07,
      "logits/chosen": 12220470.746987952,
      "logits/rejected": 12200192.83116883,
      "logps/chosen": -67.02884977409639,
      "logps/rejected": -86.62616680194805,
      "loss": 0.4601,
      "num_input_tokens_seen": 3488960,
      "rewards/chosen": 0.391221287738846,
      "rewards/margins": 0.31999301268748137,
      "rewards/rejected": 0.07122827505136466,
      "step": 135
    },
    {
      "epoch": 0.5656565656565656,
      "grad_norm": 8.963769912719727,
      "kl": 11.505388259887695,
      "learning_rate": 2.0103251919859664e-07,
      "logits/chosen": 17005351.783783782,
      "logits/rejected": 17481591.06976744,
      "logps/chosen": -67.8687645164696,
      "logps/rejected": -84.99913699127907,
      "loss": 0.4664,
      "num_input_tokens_seen": 3619488,
      "rewards/chosen": 0.48762873056772593,
      "rewards/margins": 0.3153353115060208,
      "rewards/rejected": 0.17229341906170512,
      "step": 140
    },
    {
      "epoch": 0.5858585858585859,
      "grad_norm": 10.954007148742676,
      "kl": 11.25019359588623,
      "learning_rate": 1.855512252141439e-07,
      "logits/chosen": 17510815.255813953,
      "logits/rejected": 5405319.3513513515,
      "logps/chosen": -64.95490779433139,
      "logps/rejected": -86.28069573479729,
      "loss": 0.4645,
      "num_input_tokens_seen": 3750528,
      "rewards/chosen": 0.40738589264625724,
      "rewards/margins": 0.2585567933519556,
      "rewards/rejected": 0.14882909929430163,
      "step": 145
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 11.261479377746582,
      "kl": 10.277060508728027,
      "learning_rate": 1.7033049506566743e-07,
      "logits/chosen": 6513370.352941177,
      "logits/rejected": 4333080.746666667,
      "logps/chosen": -67.4333984375,
      "logps/rejected": -85.48888671875,
      "loss": 0.4596,
      "num_input_tokens_seen": 3879840,
      "rewards/chosen": 0.4257880715762868,
      "rewards/margins": 0.29181511523676856,
      "rewards/rejected": 0.13397295633951822,
      "step": 150
    },
    {
      "epoch": 0.6262626262626263,
      "grad_norm": 10.124308586120605,
      "kl": 11.088409423828125,
      "learning_rate": 1.554318655604538e-07,
      "logits/chosen": 20788103.61904762,
      "logits/rejected": 9773402.94736842,
      "logps/chosen": -66.95327613467262,
      "logps/rejected": -87.71918688322368,
      "loss": 0.4604,
      "num_input_tokens_seen": 4009152,
      "rewards/chosen": 0.4419558842976888,
      "rewards/margins": 0.31325176305938185,
      "rewards/rejected": 0.12870412123830696,
      "step": 155
    },
    {
      "epoch": 0.6464646464646465,
      "grad_norm": 9.2560396194458,
      "kl": 12.708935737609863,
      "learning_rate": 1.4091557126568548e-07,
      "logits/chosen": 572288.6,
      "logits/rejected": 8354388.8,
      "logps/chosen": -69.33504638671874,
      "logps/rejected": -84.7302978515625,
      "loss": 0.4569,
      "num_input_tokens_seen": 4137984,
      "rewards/chosen": 0.5079422950744629,
      "rewards/margins": 0.38271362781524654,
      "rewards/rejected": 0.1252286672592163,
      "step": 160
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 11.384088516235352,
      "kl": 12.284517288208008,
      "learning_rate": 1.268403009824789e-07,
      "logits/chosen": 12551846.88607595,
      "logits/rejected": 8673782.518518519,
      "logps/chosen": -67.4817481704905,
      "logps/rejected": -85.94699435763889,
      "loss": 0.4588,
      "num_input_tokens_seen": 4267232,
      "rewards/chosen": 0.4790150606179539,
      "rewards/margins": 0.38270857766710753,
      "rewards/rejected": 0.09630648295084636,
      "step": 165
    },
    {
      "epoch": 0.6868686868686869,
      "grad_norm": 13.306822776794434,
      "kl": 13.47390079498291,
      "learning_rate": 1.1326296046939333e-07,
      "logits/chosen": 5648248.289156627,
      "logits/rejected": 21535138.90909091,
      "logps/chosen": -67.45376035391567,
      "logps/rejected": -83.3250875101461,
      "loss": 0.4484,
      "num_input_tokens_seen": 4396160,
      "rewards/chosen": 0.47821389623435145,
      "rewards/margins": 0.4056022484674455,
      "rewards/rejected": 0.07261164776690594,
      "step": 170
    },
    {
      "epoch": 0.7070707070707071,
      "grad_norm": 15.155956268310547,
      "kl": 14.57935905456543,
      "learning_rate": 1.002384423747093e-07,
      "logits/chosen": 21909163.180722892,
      "logits/rejected": 11844027.844155844,
      "logps/chosen": -65.52672016189759,
      "logps/rejected": -84.82248122970779,
      "loss": 0.4686,
      "num_input_tokens_seen": 4525184,
      "rewards/chosen": 0.38658978565629704,
      "rewards/margins": 0.2635189821007218,
      "rewards/rejected": 0.12307080355557529,
      "step": 175
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 10.826242446899414,
      "kl": 12.529523849487305,
      "learning_rate": 8.781940430763327e-08,
      "logits/chosen": 20265646.545454547,
      "logits/rejected": 14264410.666666666,
      "logps/chosen": -64.72481467507102,
      "logps/rejected": -86.30071343315973,
      "loss": 0.4629,
      "num_input_tokens_seen": 4655040,
      "rewards/chosen": 0.4655477350408381,
      "rewards/margins": 0.30869660233006335,
      "rewards/rejected": 0.15685113271077475,
      "step": 180
    },
    {
      "epoch": 0.7474747474747475,
      "grad_norm": 24.987302780151367,
      "kl": 9.990483283996582,
      "learning_rate": 7.605605594567477e-08,
      "logits/chosen": 15543620.923076924,
      "logits/rejected": 23873114.536585364,
      "logps/chosen": -65.40270057091347,
      "logps/rejected": -83.14627596227135,
      "loss": 0.4621,
      "num_input_tokens_seen": 4781952,
      "rewards/chosen": 0.43369850745567906,
      "rewards/margins": 0.31210866072835436,
      "rewards/rejected": 0.1215898467273247,
      "step": 185
    },
    {
      "epoch": 0.7676767676767676,
      "grad_norm": 11.170469284057617,
      "kl": 11.813103675842285,
      "learning_rate": 6.499595603891564e-08,
      "logits/chosen": 5372270.702702703,
      "logits/rejected": -68666.04651162791,
      "logps/chosen": -64.62088260135135,
      "logps/rejected": -85.26564771075581,
      "loss": 0.4749,
      "num_input_tokens_seen": 4911616,
      "rewards/chosen": 0.37521408699654246,
      "rewards/margins": 0.22930142865999179,
      "rewards/rejected": 0.14591265833655068,
      "step": 190
    },
    {
      "epoch": 0.7878787878787878,
      "grad_norm": 10.689099311828613,
      "kl": 11.106500625610352,
      "learning_rate": 5.4683820131872724e-08,
      "logits/chosen": 2254639.2195121953,
      "logits/rejected": 14054752.82051282,
      "logps/chosen": -63.199052019817074,
      "logps/rejected": -85.95875901442308,
      "loss": 0.4479,
      "num_input_tokens_seen": 5042080,
      "rewards/chosen": 0.5079716938297923,
      "rewards/margins": 0.4747716743846176,
      "rewards/rejected": 0.033200019445174776,
      "step": 195
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 12.639554023742676,
      "kl": 11.542754173278809,
      "learning_rate": 4.5161339780327576e-08,
      "logits/chosen": 11855943.89041096,
      "logits/rejected": 19782757.51724138,
      "logps/chosen": -65.6914196275685,
      "logps/rejected": -84.32436467313218,
      "loss": 0.4595,
      "num_input_tokens_seen": 5169952,
      "rewards/chosen": 0.4967799774587971,
      "rewards/margins": 0.3352322398987441,
      "rewards/rejected": 0.16154773756005297,
      "step": 200
    },
    {
      "epoch": 0.8080808080808081,
      "eval_logits/chosen": 20884344.19512195,
      "eval_logits/rejected": 8775205.743589744,
      "eval_logps/chosen": -66.47020293445122,
      "eval_logps/rejected": -83.23796824919872,
      "eval_loss": 0.45935431122779846,
      "eval_rewards/chosen": 0.5384779674250905,
      "eval_rewards/margins": 0.3441636954493042,
      "eval_rewards/rejected": 0.19431427197578627,
      "eval_runtime": 23.7281,
      "eval_samples_per_second": 3.372,
      "eval_steps_per_second": 0.843,
      "kl": 7.150491714477539,
      "num_input_tokens_seen": 5169952,
      "step": 200
    },
    {
      "epoch": 0.8282828282828283,
      "grad_norm": 10.542067527770996,
      "kl": 14.266122817993164,
      "learning_rate": 3.6467013994023325e-08,
      "logits/chosen": 16887026.871794872,
      "logits/rejected": 31607676.87804878,
      "logps/chosen": -65.78305288461539,
      "logps/rejected": -85.66090058117378,
      "loss": 0.465,
      "num_input_tokens_seen": 5298528,
      "rewards/chosen": 0.4516463157458183,
      "rewards/margins": 0.30157205475502424,
      "rewards/rejected": 0.1500742609907941,
      "step": 205
    },
    {
      "epoch": 0.8484848484848485,
      "grad_norm": 13.39328670501709,
      "kl": 13.84505558013916,
      "learning_rate": 2.863599358669755e-08,
      "logits/chosen": 8059486.476190476,
      "logits/rejected": 7925952.0,
      "logps/chosen": -67.24676804315476,
      "logps/rejected": -84.26215563322368,
      "loss": 0.4627,
      "num_input_tokens_seen": 5428256,
      "rewards/chosen": 0.47778206779843285,
      "rewards/margins": 0.3120754081802559,
      "rewards/rejected": 0.1657066596181769,
      "step": 210
    },
    {
      "epoch": 0.8686868686868687,
      "grad_norm": 9.306497573852539,
      "kl": 14.087210655212402,
      "learning_rate": 2.1699939062738648e-08,
      "logits/chosen": 19553030.91891892,
      "logits/rejected": 8948697.302325582,
      "logps/chosen": -65.78959697001689,
      "logps/rejected": -88.14454828306685,
      "loss": 0.45,
      "num_input_tokens_seen": 5557952,
      "rewards/chosen": 0.5854773650298247,
      "rewards/margins": 0.4710630612280442,
      "rewards/rejected": 0.11441430380178053,
      "step": 215
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 8.996216773986816,
      "kl": 14.023937225341797,
      "learning_rate": 1.5686892615024676e-08,
      "logits/chosen": 620456.96,
      "logits/rejected": 14254451.952941176,
      "logps/chosen": -68.04496744791666,
      "logps/rejected": -86.85975413602941,
      "loss": 0.4538,
      "num_input_tokens_seen": 5687040,
      "rewards/chosen": 0.5566402180989584,
      "rewards/margins": 0.41483239267386646,
      "rewards/rejected": 0.1418078254250919,
      "step": 220
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 19.600744247436523,
      "kl": 11.805475234985352,
      "learning_rate": 1.0621164751451833e-08,
      "logits/chosen": 12051645.569620254,
      "logits/rejected": 12611533.432098765,
      "logps/chosen": -66.29129994066456,
      "logps/rejected": -85.90596064814815,
      "loss": 0.4639,
      "num_input_tokens_seen": 5817152,
      "rewards/chosen": 0.43035328539111944,
      "rewards/margins": 0.29047754373861895,
      "rewards/rejected": 0.1398757416525005,
      "step": 225
    },
    {
      "epoch": 0.9292929292929293,
      "grad_norm": 9.736303329467773,
      "kl": 10.68354606628418,
      "learning_rate": 6.523236008516342e-09,
      "logits/chosen": 19780401.87012987,
      "logits/rejected": 25375888.963855423,
      "logps/chosen": -64.2320413961039,
      "logps/rejected": -85.63196536144578,
      "loss": 0.465,
      "num_input_tokens_seen": 5944480,
      "rewards/chosen": 0.4729325430733817,
      "rewards/margins": 0.32396509889481195,
      "rewards/rejected": 0.14896744417856975,
      "step": 230
    },
    {
      "epoch": 0.9494949494949495,
      "grad_norm": 9.908862113952637,
      "kl": 11.605594635009766,
      "learning_rate": 3.4096741493194193e-09,
      "logits/chosen": -8375371.2,
      "logits/rejected": 7381449.6,
      "logps/chosen": -66.27982177734376,
      "logps/rejected": -89.22088623046875,
      "loss": 0.4598,
      "num_input_tokens_seen": 6074688,
      "rewards/chosen": 0.5002464294433594,
      "rewards/margins": 0.38919639587402344,
      "rewards/rejected": 0.11105003356933593,
      "step": 235
    },
    {
      "epoch": 0.9696969696969697,
      "grad_norm": 11.206439018249512,
      "kl": 8.710221290588379,
      "learning_rate": 1.2930671807592497e-09,
      "logits/chosen": 16197574.4,
      "logits/rejected": 20665046.4,
      "logps/chosen": -69.4001708984375,
      "logps/rejected": -83.4201904296875,
      "loss": 0.4667,
      "num_input_tokens_seen": 6204224,
      "rewards/chosen": 0.379030442237854,
      "rewards/margins": 0.2585079193115234,
      "rewards/rejected": 0.12052252292633056,
      "step": 240
    },
    {
      "epoch": 0.98989898989899,
      "grad_norm": 13.42957878112793,
      "kl": 10.205140113830566,
      "learning_rate": 1.819724607191042e-10,
      "logits/chosen": 5778052.21978022,
      "logits/rejected": 12925844.405797102,
      "logps/chosen": -66.06911057692308,
      "logps/rejected": -86.08443727355072,
      "loss": 0.4439,
      "num_input_tokens_seen": 6336512,
      "rewards/chosen": 0.4925417218889509,
      "rewards/margins": 0.4254889636306289,
      "rewards/rejected": 0.067052758258322,
      "step": 245
    },
    {
      "epoch": 0.997979797979798,
      "num_input_tokens_seen": 6388096,
      "step": 247,
      "total_flos": 2.470129418816717e+16,
      "train_loss": 0.47427154118232884,
      "train_runtime": 4471.7623,
      "train_samples_per_second": 1.771,
      "train_steps_per_second": 0.055
    }
  ],
  "logging_steps": 5,
  "max_steps": 247,
  "num_input_tokens_seen": 6388096,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.470129418816717e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
